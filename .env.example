# Lemmy Instance Configuration
LEMMY_INSTANCE_URL=https://poptalk.scrubbles.tech
VITE_LEMMY_INSTANCE_URL=https://poptalk.scrubbles.tech

# Backend API Configuration
# For local development (different ports)
BACKEND_API_URL=http://localhost:3001
VITE_BACKEND_API_URL=http://localhost:3001
# For production (same origin via reverse proxy), use:
# VITE_BACKEND_API_URL=/api

# PostgreSQL Database Configuration (used by backend)
# Choose ONE of the following options:
#
# Option 1: Connection string (recommended for production/Kubernetes)
# If you set DB_CONNECTION_STRING, you don't need DB_HOST, DB_PORT, etc.
# DB_CONNECTION_STRING=postgresql://user:password@host:port/database?sslmode=require
#
# Option 2: Individual parameters (recommended for local development)
# If you don't set DB_CONNECTION_STRING, these individual parameters are required:
DB_HOST=localhost
DB_PORT=5432
DB_NAME=lemmy
DB_USER=lemmy
DB_PASSWORD=
#
# Pool configuration (optional, defaults to 20)
# DB_MAX_CONNECTIONS=20
#
# SSL configuration (for self-signed certificates)
# Set to 'false' to accept self-signed certificates (defaults to true)
# DB_SSL_REJECT_UNAUTHORIZED=false

# CORS Configuration
CORS_ORIGIN=http://localhost:3000

# OpenAI-compatible API Configuration (optional, for AI summaries)
# Set this to your local LLM provider endpoint
# VITE_OPENAI_API_URL=http://localhost:1234/v1
# VITE_OPENAI_API_KEY=optional-api-key
